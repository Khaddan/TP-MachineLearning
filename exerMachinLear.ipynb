{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Charger le jeu de données initial\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mHosing.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le jeu de données initial\n",
    "df = pd.read_csv(\"Hosing.csv\")\n",
    "\n",
    "# Sélectionner les colonnes nécessaires\n",
    "selected_columns = [\"area\", \"bedrooms\", \"bathrooms\", \"price\"]\n",
    "new_df = df[selected_columns]\n",
    "\n",
    "# Afficher le nouveau jeu de données\n",
    "print(new_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le jeu de données\n",
    "df = pd.read_csv(\"Housing.csv\")\n",
    "\n",
    "# Sélectionner les colonnes à standardiser\n",
    "columns_to_standardize = [\"feature1\", \"feature2\", \"feature3\"]\n",
    "\n",
    "# Créer un objet StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Effectuer la standardisation sur les colonnes sélectionnées\n",
    "df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "# Afficher le jeu de données standardisé\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le jeu de données\n",
    "df = pd.read_csv(\"Housing.csv\")\n",
    "\n",
    "# Séparer les features (X) de la target (y)\n",
    "X = df.drop(\"target\", axis=1)  # Remplacer \"target\" par le nom de votre colonne target\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(X, y):\n",
    "    # Ajouter une colonne de 1 à X pour représenter le biais\n",
    "    X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "    \n",
    "    # Calculer les poids avec l'équation normale\n",
    "    weights = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    \n",
    "    # Extraire le biais et les poids\n",
    "    bias = weights[0]\n",
    "    weights = weights[1:]\n",
    "    \n",
    "    return bias, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(X, y, num_iterations=100, learning_rate=0.01):\n",
    "    # Ajouter une colonne de 1 à X pour représenter le biais\n",
    "    X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "    \n",
    "    # Initialiser les poids aléatoirement\n",
    "    num_features = X.shape[1]\n",
    "    weights = np.random.randn(num_features)\n",
    "    \n",
    "    # Mémoriser les valeurs de MSE relatives aux itérations\n",
    "    mse_values = []\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        # Calculer les prédictions avec les poids actuels\n",
    "        predictions = X @ weights\n",
    "        \n",
    "        # Calculer l'erreur\n",
    "        error = predictions - y\n",
    "        \n",
    "        # Calculer le MSE\n",
    "        mse = np.mean(error ** 2)\n",
    "        \n",
    "        # Mémoriser la valeur de MSE\n",
    "        mse_values.append(mse)\n",
    "        \n",
    "        # Mettre à jour les poids en utilisant la descente de gradient\n",
    "        gradient = 2 * X.T @ error / X.shape[0]\n",
    "        weights -= learning_rate * gradient\n",
    "    \n",
    "    # Tracer le graphique de l'évolution de MSE en fonction des itérations\n",
    "    plt.plot(range(num_iterations), mse_values)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('Evolution de MSE en fonction des itérations')\n",
    "    plt.show()\n",
    "    \n",
    "    # Extraire le biais et les poids\n",
    "    bias = weights[0]\n",
    "    weights = weights[1:]\n",
    "    \n",
    "    return bias, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_data():\n",
    "    # Générer des données aléatoires pour l'exemple\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(100, 1)\n",
    "    y = 3 * X.squeeze() + 2 + 0.1 * np.random.randn(100)\n",
    "    return X, y\n",
    "\n",
    "def train(X, y, num_iterations=100, learning_rate=0.01):\n",
    "    X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "    \n",
    "    num_features = X.shape[1]\n",
    "    weights = np.random.randn(num_features)\n",
    "    \n",
    "    mse_values = []\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        # Calculer les prédictions avec les poids actuels\n",
    "        predictions = X @ weights\n",
    "        \n",
    "        # Calculer l'erreur\n",
    "        error = predictions - y\n",
    "        \n",
    "        # Calculer le MSE\n",
    "        mse = np.mean(error ** 2)\n",
    "        \n",
    "        # Mémoriser la valeur de MSE\n",
    "        mse_values.append(mse)\n",
    "        \n",
    "        # Mettre à jour les poids en utilisant la descente de gradient\n",
    "        gradient = 2 * X.T @ error / X.shape[0]\n",
    "        weights -= learning_rate * gradient\n",
    "    \n",
    "    # Tracer le graphique de l'évolution de MSE en fonction des itérations\n",
    "    plt.plot(range(num_iterations), mse_values)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('Evolution de MSE en fonction des itérations')\n",
    "    plt.show()\n",
    "    \n",
    "    # Extraire le biais et les poids\n",
    "    bias = weights[0]\n",
    "    weights = weights[1:]\n",
    "    \n",
    "    return bias, weights\n",
    "\n",
    "# Générer des données d'exemple\n",
    "X, y = generate_data()\n",
    "\n",
    "# Tester la fonction train avec différents réglages\n",
    "epochs_values = [50, 100, 200, 500]\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "\n",
    "for epochs in epochs_values:\n",
    "    for learning_rate in learning_rates:\n",
    "        print(f\"Training with epochs={epochs}, learning_rate={learning_rate}\")\n",
    "        bias, weights = train(X, y, num_iterations=epochs, learning_rate=learning_rate)\n",
    "        print(\"Bias:\", bias)\n",
    "        print(\"Weights:\", weights)\n",
    "        print(\"==============================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(X, bias, weights):\n",
    "    # Ajouter une colonne de 1 à X pour représenter le biais\n",
    "    X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "    \n",
    "    # Calculer les prédictions en utilisant les poids et le biais\n",
    "    predictions = X @ np.concatenate(([bias], weights))\n",
    "    \n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    # Calculer l'erreur entre les vraies valeurs et les prédictions\n",
    "    error = y_true - y_pred\n",
    "    \n",
    "    # Calculer le MSE\n",
    "    mse = np.mean(error ** 2)\n",
    "    \n",
    "    return mse\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
